#!/usr/bin/env tsx

import * as fs from 'fs';
import * as path from 'path';
import * as readline from 'readline';
import { config } from 'dotenv';

// Load environment variables
config();

interface TradeData {
  coin: string;
  px: string;
  sz: string;
  side: string;
  time: number;
  startPosition: string;
  dir: string;
  closedPnl: string;
  hash: string;
  oid: number;
  crossed: boolean;
  fee: string;
  tid: number;
  cloid?: string;
  feeToken: string;
  twapId?: number | null; // Optional - not all trades have TWAP IDs
}

interface BlockRecord {
  local_time: string;
  block_time: string;
  block_number: number;
  events: Array<[string, TradeData]>; // [user_address, trade_data]
}

interface Stats {
  filesProcessed: number;
  linesRead: number;
  tradesWritten: number;
  participantsWritten: number;
  tradesSkipped: number;
  errors: number;
  startTime: number;
}

// Check if a trade has at least one participant with twap_id
function tradeHasTwapId(participants: Array<[string, TradeData]>): boolean {
  return participants.some(([_, trade]) => trade.twapId !== null && trade.twapId !== undefined);
}

// Escape CSV fields that contain special characters
function escapeCsvField(value: any): string {
  if (value === null || value === undefined) {
    return '\\N'; // PostgreSQL NULL representation
  }
  
  let strValue = String(value);
  
  // Escape backslashes and double quotes
  strValue = strValue.replace(/\\/g, '\\\\').replace(/"/g, '""');
  
  // If the string contains commas, newlines, or double quotes, enclose in double quotes
  if (strValue.includes(',') || strValue.includes('\n') || strValue.includes('"')) {
    return `"${strValue}"`;
  }
  
  return strValue;
}

// Track the next trade ID to assign
// This will be initialized from command-line argument (e.g., max(id) + 1 from database)
let nextTradeId = 1;

async function processFile(
  filePath: string,
  tradesWriter: fs.WriteStream,
  participantsWriter: fs.WriteStream,
  stats: Stats
): Promise<void> {
  try {
    const fileStream = fs.createReadStream(filePath, { encoding: 'utf-8' });
    const rl = readline.createInterface({
      input: fileStream,
      crlfDelay: Infinity
    });
    
    for await (const line of rl) {
      const trimmedLine = line.trim();
      if (trimmedLine.length === 0) continue;
      
      stats.linesRead++;
      
      try {
        const block: BlockRecord = JSON.parse(trimmedLine);
        
        // Skip blocks with no events
        if (!block.events || block.events.length === 0) {
          continue;
        }
        
        // Group ALL events by tid (trade ID) first - each tid represents a unique trade
        const tradesByTid = new Map<number, Array<[string, TradeData]>>();
        
        for (const [userAddress, trade] of block.events) {
          // Skip if trade doesn't have required fields
          if (!trade.tid || !userAddress) {
            continue;
          }
          
          if (!tradesByTid.has(trade.tid)) {
            tradesByTid.set(trade.tid, []);
          }
          tradesByTid.get(trade.tid)!.push([userAddress, trade]);
        }
        
        // Process each unique trade - include ALL participants if at least one has twapId
        for (const [tid, participants] of Array.from(tradesByTid.entries())) {
          if (participants.length === 0) continue;
          
          // Check if this trade has at least one participant with twapId
          if (!tradeHasTwapId(participants)) {
            stats.tradesSkipped++;
            continue;
          }
          
          // Use the first participant's trade data for the trade record
          const firstTrade = participants[0][1];
          
          // Assign sequential trade ID
          const tradeId = nextTradeId++;
          
          // Convert Unix timestamp (milliseconds) to ISO 8601
          const timeISO = new Date(firstTrade.time).toISOString();
          
          // Write trade to CSV (with explicit ID) - NO side column
          const tradeRow = [
            tradeId,
            escapeCsvField(firstTrade.coin),
            escapeCsvField(timeISO),
            escapeCsvField(firstTrade.px),
            escapeCsvField(firstTrade.sz),
            escapeCsvField(firstTrade.hash),
            escapeCsvField(firstTrade.dir || null), // Using 'dir' as trade_dir_override
          ].join(',');
          
          tradesWriter.write(tradeRow + '\n');
          stats.tradesWritten++;
          
          // Write ALL participants for this trade (WITH side column)
          for (const [userAddress, trade] of participants) {
            const participantRow = [
              tradeId, // trade_id (foreign key)
              escapeCsvField(userAddress),
              escapeCsvField(trade.side), // 'A' = Ask/Sell, 'B' = Bid/Buy
              escapeCsvField(trade.startPosition),
              escapeCsvField(trade.oid),
              escapeCsvField(trade.twapId),
              escapeCsvField(trade.cloid || null),
            ].join(',');
            
            participantsWriter.write(participantRow + '\n');
            stats.participantsWritten++;
          }
        }
      } catch (error) {
        stats.errors++;
        // Don't log every parsing error to avoid spam - just increment counter
      }
    }
    
    stats.filesProcessed++;
  } catch (error) {
    console.error(`  ‚ùå Error reading file ${path.basename(filePath)}:`, error);
    stats.errors++;
  }
}

// Find all day directories (YYYYMMDD format) and their hour files
function findDayDirectories(hourlyDir: string): Map<string, string[]> {
  const dayDirs = new Map<string, string[]>(); // Map of dayDir -> [hourFiles]
  
  const items = fs.readdirSync(hourlyDir);
  for (const item of items) {
    if (item.startsWith('.')) continue; // Skip hidden files
    
    const fullPath = path.join(hourlyDir, item);
    const stat = fs.statSync(fullPath);
    
    // Look for YYYYMMDD directories
    if (stat.isDirectory() && /^\d{8}$/.test(item)) {
      const hourFiles: string[] = [];
      
      // Get all hour files in this day directory
      const hourItems = fs.readdirSync(fullPath);
      for (const hourItem of hourItems) {
        if (hourItem.startsWith('.')) continue; // Skip hidden files
        if (hourItem.endsWith('.csv')) continue; // Skip CSV output files
        
        const hourPath = path.join(fullPath, hourItem);
        const hourStat = fs.statSync(hourPath);
        if (hourStat.isFile()) {
          hourFiles.push(hourPath);
        }
      }
      
      if (hourFiles.length > 0) {
        dayDirs.set(fullPath, hourFiles);
      }
    }
  }
  
  return dayDirs;
}

function formatDuration(ms: number): string {
  const seconds = Math.floor(ms / 1000);
  const minutes = Math.floor(seconds / 60);
  const hours = Math.floor(minutes / 60);
  
  if (hours > 0) return `${hours}h ${minutes % 60}m ${seconds % 60}s`;
  if (minutes > 0) return `${minutes}m ${seconds % 60}s`;
  return `${seconds}s`;
}

async function main() {
  const args = process.argv.slice(2);
  const sourceDir = args.find(arg => !arg.startsWith('--')) || './hl-data/node_fills_by_block/hourly';
  
  // Parse --start-id argument
  const startIdArg = args.find(arg => arg.startsWith('--start-id='));
  
  // Check for .last_trade_id file (at project root, shared across both generate scripts)
  const trackingFile = path.join(process.cwd(), '.last_trade_id');
  let usedTrackingFile = false;
  
  if (startIdArg) {
    // Manual override takes precedence
    const startId = parseInt(startIdArg.split('=')[1]);
    if (isNaN(startId) || startId < 1) {
      console.error('‚ùå Error: --start-id must be a positive integer');
      process.exit(1);
    }
    nextTradeId = startId;
  } else if (fs.existsSync(trackingFile)) {
    // Resume from tracking file
    try {
      const lastId = parseInt(fs.readFileSync(trackingFile, 'utf-8').trim());
      if (!isNaN(lastId) && lastId > 0) {
        nextTradeId = lastId + 1;
        usedTrackingFile = true;
        console.log(`üìå Found tracking file: resuming from ID ${nextTradeId.toLocaleString()}`);
      }
    } catch (error) {
      console.warn(`‚ö†Ô∏è  Could not read tracking file, starting from 1`);
    }
  }
  
  console.log('üöÄ TWAP Trade CSV Generator for PostgreSQL COPY');
  console.log('='.repeat(70));
  console.log(`Source directory: ${sourceDir}`);
  console.log(`Output: One CSV pair per day in source directory`);
  
  let idSource = ' (default)';
  if (startIdArg) idSource = ' (from --start-id)';
  else if (usedTrackingFile) idSource = ' (from .last_trade_id)';
  console.log(`Starting trade ID: ${nextTradeId.toLocaleString()}${idSource}`);
  
  console.log(`Filter: Include ALL participants of trades with at least one twapId`);
  console.log(`Note: Files without TWAP trades will be skipped`);
  console.log('='.repeat(70));

  if (!fs.existsSync(sourceDir)) {
    console.error(`‚ùå Error: Directory not found: ${sourceDir}`);
    process.exit(1);
  }

  console.log('\nüîç Scanning for day directories (YYYYMMDD)...');
  const dayDirs = findDayDirectories(sourceDir);
  const dayCount = dayDirs.size;
  
  if (dayCount === 0) {
    console.error(`‚ùå No day directories found in ${sourceDir}`);
    console.log('Expected format: hourly/YYYYMMDD/HH (e.g., hourly/20250822/0, hourly/20250822/1, ...)');
    process.exit(1);
  }
  
  // Show date range
  const sortedDayNames = Array.from(dayDirs.keys())
    .map(dir => path.basename(dir))
    .sort();
  const firstDay = sortedDayNames[0];
  const lastDay = sortedDayNames[sortedDayNames.length - 1];
  
  console.log(`üìÅ Found ${dayCount} day directories to process`);
  console.log(`üìÖ Date range: ${firstDay} to ${lastDay}`);
  
  const overallStats: Stats = {
    filesProcessed: 0,
    linesRead: 0,
    tradesWritten: 0,
    participantsWritten: 0,
    tradesSkipped: 0,
    errors: 0,
    startTime: Date.now(),
  };

  let processedDays = 0;
  const sortedDays = Array.from(dayDirs.entries()).sort((a, b) => a[0].localeCompare(b[0]));

  // Process each day
  for (const [dayDir, hourFiles] of sortedDays) {
    const dayName = path.basename(dayDir);
    try {
      console.log(`\n${'='.repeat(70)}`);
      console.log(`üìÖ Processing ${dayName} (${hourFiles.length} hour files)`);
      console.log(`${'='.repeat(70)}`);
      
      // Create CSV files for this day
      const tradesPath = path.join(dayDir, `trades_${dayName}.csv`);
      const participantsPath = path.join(dayDir, `trade_participants_${dayName}.csv`);
      
      // Check if files already exist and warn about overwriting
      const tradesExists = fs.existsSync(tradesPath);
      const participantsExists = fs.existsSync(participantsPath);
      
      if (tradesExists || participantsExists) {
        console.log(`‚ö†Ô∏è  Overwriting existing CSV files`);
      }
      
      console.log(`üìù Output files:`);
      console.log(`  - ${tradesPath}`);
      console.log(`  - ${participantsPath}`);
      
      const tradesWriter = fs.createWriteStream(tradesPath);
      const participantsWriter = fs.createWriteStream(participantsPath);
      
      const dayStats: Stats = {
        filesProcessed: 0,
        linesRead: 0,
        tradesWritten: 0,
        participantsWritten: 0,
        tradesSkipped: 0,
        errors: 0,
        startTime: Date.now(),
      };
      
      // Process all hour files for this day
      for (let i = 0; i < hourFiles.length; i++) {
        await processFile(hourFiles[i], tradesWriter, participantsWriter, dayStats);
        
        // Print progress every 5 files
        if ((i + 1) % 5 === 0 || i === hourFiles.length - 1) {
          const elapsed = Date.now() - dayStats.startTime;
          const rate = dayStats.tradesWritten / Math.max(elapsed / 1000, 1);
          
          console.log(`  üìä Progress: ${i + 1}/${hourFiles.length} files | Trades: ${dayStats.tradesWritten.toLocaleString()} | Rate: ${rate.toFixed(2)}/sec`);
        }
      }
      
      // Close write streams (register listeners BEFORE calling .end())
      console.log(`  üîí Closing streams...`);
      
      // Create promises BEFORE calling .end() to avoid missing the finish event
      const tradesFinished = new Promise<void>((resolve) => {
        tradesWriter.on('finish', () => {
          console.log(`    ‚úì Trades stream finished`);
          resolve();
        });
      });
      
      const participantsFinished = new Promise<void>((resolve) => {
        participantsWriter.on('finish', () => {
          console.log(`    ‚úì Participants stream finished`);
          resolve();
        });
      });
      
      // Now call .end()
      tradesWriter.end();
      participantsWriter.end();
      
      // Wait for streams to finish with timeout
      console.log(`  ‚è≥ Waiting for streams to finish...`);
      await Promise.race([
        tradesFinished,
        new Promise<void>((_, reject) => setTimeout(() => reject(new Error('Trades stream timeout')), 10000))
      ]);
      
      await Promise.race([
        participantsFinished,
        new Promise<void>((_, reject) => setTimeout(() => reject(new Error('Participants stream timeout')), 10000))
      ]);
      
      console.log(`  ‚úì Streams closed`);
      
      // Day summary
      const dayDuration = Date.now() - dayStats.startTime;
      const dayRate = dayStats.tradesWritten / Math.max(dayDuration / 1000, 1);
      
      console.log(`  üìä Computing summary...`);
      
      if (dayStats.tradesWritten === 0) {
        console.log(`\n  ‚ö†Ô∏è  ${dayName}: No TWAP trades found (skipping CSV creation)`);
        // Delete empty CSV files
        try {
          if (fs.existsSync(tradesPath)) fs.unlinkSync(tradesPath);
          if (fs.existsSync(participantsPath)) fs.unlinkSync(participantsPath);
        } catch (e) { /* ignore */ }
      } else {
        console.log(`\n  ‚úÖ ${dayName} complete:`);
        console.log(`     Files:        ${dayStats.filesProcessed}`);
        console.log(`     Trades:       ${dayStats.tradesWritten.toLocaleString()}`);
        console.log(`     Participants: ${dayStats.participantsWritten.toLocaleString()}`);
        console.log(`     Skipped:      ${dayStats.tradesSkipped.toLocaleString()}`);
        if (dayStats.errors > 0) {
          console.log(`     Parse errors: ${dayStats.errors.toLocaleString()}`);
        }
        console.log(`     Duration:     ${formatDuration(dayDuration)}`);
        console.log(`     Rate:         ${dayRate.toFixed(2)} trades/sec`);
      }
    
      // Add to overall stats
      overallStats.filesProcessed += dayStats.filesProcessed;
      overallStats.linesRead += dayStats.linesRead;
      overallStats.tradesWritten += dayStats.tradesWritten;
      overallStats.participantsWritten += dayStats.participantsWritten;
      overallStats.tradesSkipped += dayStats.tradesSkipped;
      overallStats.errors += dayStats.errors;
      
      processedDays++;
    } catch (error) {
      console.error(`\n‚ùå Fatal error processing ${path.basename(dayDir)}:`, error);
      console.error('Continuing to next day...\n');
      overallStats.errors++;
    }
  }

  console.log(`\n‚úì Loop completed. Processed ${processedDays} days.`);
  
  // Final summary
  const totalDuration = Date.now() - overallStats.startTime;
  const finalRate = overallStats.tradesWritten / Math.max(totalDuration / 1000, 1);
  
  console.log('\n' + '='.repeat(70));
  console.log('‚úÖ All Days Complete!');
  console.log('üìä Overall Summary');
  console.log('='.repeat(70));
  console.log(`Days processed:        ${processedDays}`);
  console.log(`Total files processed: ${overallStats.filesProcessed}`);
  console.log(`Total lines read:      ${overallStats.linesRead.toLocaleString()}`);
  console.log(`Trades written:        ${overallStats.tradesWritten.toLocaleString()}`);
  console.log(`Participants written:  ${overallStats.participantsWritten.toLocaleString()}`);
  console.log(`Trades skipped:        ${overallStats.tradesSkipped.toLocaleString()}`);
  console.log(`Total errors:          ${overallStats.errors.toLocaleString()}`);
  console.log(`Total duration:        ${formatDuration(totalDuration)}`);
  console.log(`Overall rate:          ${finalRate.toFixed(2)} trades/sec`);
  console.log('='.repeat(70));

  if (overallStats.tradesWritten > 0) {
    console.log('\nüí° Next Steps:');
    console.log('='.repeat(70));
    console.log('Import the generated CSVs to your database:');
    console.log('');
    console.log('  npm run import:node-fills-by-block <source_directory> -- --staging-only');
    console.log('');
    console.log('This will load data to staging tables for inspection before production migration.');
    console.log(`Final trade ID will be: ${(nextTradeId - 1).toLocaleString()}`);
    console.log('='.repeat(70));
  } else {
    console.log('\n‚ö†Ô∏è  No TWAP trades found in any of the processed files.');
    console.log('This might mean:');
    console.log('  - The files don\'t contain TWAP data (missing twapId field)');
    console.log('  - The date range doesn\'t have any TWAP trades');
    console.log('  - The data format is different than expected');
  }

  if (overallStats.errors > 0) {
    console.error(`\n‚ö†Ô∏è  Completed with ${overallStats.errors} errors. Check logs above.`);
    process.exit(1);
  } else {
    console.log('\nüéâ All CSVs generated successfully!');
    
    // Save final trade ID to tracking file
    if (overallStats.tradesWritten > 0) {
      const finalId = nextTradeId - 1; // Last ID used
      try {
        fs.writeFileSync(trackingFile, finalId.toString(), 'utf-8');
        console.log(`üìå Saved final trade ID (${finalId.toLocaleString()}) to .last_trade_id`);
        console.log(`   Next run (node_trades or node_fills_by_block) will resume from ID ${(finalId + 1).toLocaleString()}`);
      } catch (error) {
        console.warn(`‚ö†Ô∏è  Could not write tracking file: ${error}`);
      }
    }
  }
}

main().catch((error) => {
  console.error('\n‚ùå FATAL ERROR:');
  console.error(error);
  process.exit(1);
});
